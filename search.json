[
  {
    "objectID": "nextflow_crash_course.html",
    "href": "nextflow_crash_course.html",
    "title": "Foundational skills: Nextflow crash course",
    "section": "",
    "text": "Nextflow is very well documented and there is some great in-depth training material available.\nSee the official Nextflow Training, or Introduction to Bioinformatics workflows with Nextflow and nf-core for a comprehensive introduction and deeper dive.\nHere we will focus on downloading, configuring and running a Nextflow pipeline for de novo protein binder design.\n\n\nFollow the official Nextflow installation instructions - they are clear, and work. You don’t need sudo to install Nextflow.\n\nTip: Java 17+, a dependency of Nextflow, is available as a module on the M3 HPC cluster as module load java.\n\n\n\n\nOption 1: Download the pipeline code from the Github repository.\ngit clone https://github.com/Australian-Protein-Design-Initiative/nf-binder-design\ncd nf-binder-design\nOption 2: Use Nextflow pull\nnextflow pull Australian-Protein-Design-Initiative/nf-binder-design\n\n# or for a specific version / release\n# nextflow pull -r 0.1.4 Australian-Protein-Design-Initiative/nf-binder-design\n\n# You can see some info about what you just pulled\nnextflow info Australian-Protein-Design-Initiative/nf-binder-design\n\nIn the case of option 2, Nextflow git clones for you into: ~/.nextflow/assets/Australian-Protein-Design-Initiative/nf-binder-design - so you can find things like the default config files in the repository there.\n\n\n\n\nMost Nextflow pipelines (especially nf-core flavoured ones), come with sensible pre-configured defaults, but you’ll often need to override or modify some of the settings for your particular computing environment, data and preferences.\nWe will assume here we are running on an HPC cluster using SLURM. Nextflow submits sbatch jobs to the SLURM queue on your behalf, and needs to specify resources and partition settings for each job.\nYou can override defaults by creating a nextflow.config file in the working directory where you run the pipeline. The most common thing you’ll need to do is modify the resources and parition settings for a specific task (‘process’ in Nextflow terminology).\n// nextflow.config\nprocess {\n    withName: BINDCRAFT {\n        // time, cpus, memory (non-GPU) are specified OUTSIDE clusterOptions\n        time = 2.hours\n        memory = '32g'\n        cpus = 16\n\n        // Everything else SLURM sbatch specific goes in clusterOptions\n        // eg, speficying a specific GPU partition\n        clusterOptions = \"--gres=gpu:1 --partition=gpu\"\n    }\n}\n\n\n\nA wrapper script is a convenient way to record all the commandline arguments you used to run the pipeline and simplify re-running after failures / modifications. We will create a script called run.sh to run the pipeline (and do chmod +x run.sh to make it executable).\n#!/bin/bash\n###\n## run.sh\n###\n\n# We will assume here that you have done `nextflow pull` so the pipeline code is in $HOME/.nextflow/assets/Australian-Protein-Design-Initiative/nf-binder-design\nPIPELINE_DIR=$HOME/.nextflow/assets/Australian-Protein-Design-Initiative/nf-binder-design\n\nDATESTAMP=$(date +%Y%m%d_%H%M%S)\n\nnextflow run ${PIPELINE_DIR}/bindcraft.nf \\\n  -c ${PIPELINE_DIR}/conf/platforms/m3.config \\\n  --input_pdb 'input/PDL1.pdb' \\\n  --outdir results \\\n  --target_chains \"A\" \\\n  --hotspot_res \"A56\" \\\n  --binder_length_range \"65-120\" \\\n  --bindcraft_n_traj 4 \\\n  --bindcraft_batch_size 1 \\\n  -profile slurm \\\n  -resume \\\n  -with-report results/logs/report_${DATESTAMP}.html \\\n  -with-trace results/logs/trace_${DATESTAMP}.txt\nWe include a specific config for the M3 HPC cluster using -c ${PIPELINE_DIR}/conf/platforms/m3.config. If you view this file, you’ll see all the resource and partition settings tuned this particular HPC cluster. You can copy these settings to your own nextflow.config (as above) and override as required.\nWe also include -resume to resume a previous run if it exists - this is benign if it’s the first time you’re running the pipeline, but is important to ensure the pipeline resumes where it left off if you need to restart it in the event of a failure.\n\nNextflow itself is relatively light weight in resource usage, but you can also turn this into an SBATCH script if your HPC adminstrators prefer you to not run it on the login node.\n\n\n\nAn alternative to putting all the “--double-dash” pipeline parameters in the wrapper script is to use a JSON file like:\n{\n    \"input_pdb\": \"input/PDL1.pdb\",\n    \"outdir\": \"results\",\n    \"target_chains\": \"A\",\n    \"hotspot_res\": \"A56\",\n    \"binder_length_range\": \"65-120\",\n    \"bindcraft_n_traj\": 4,\n    \"bindcraft_batch_size\": 1\n}\nAnd run like:\n#!/bin/bash\n###\n## run-with-params.sh\n###\n\n# We will assume here that you have done `nextflow pull` so the pipeline code is in $HOME/.nextflow/assets/Australian-Protein-Design-Initiative/nf-binder-design\nPIPELINE_DIR=$HOME/.nextflow/assets/Australian-Protein-Design-Initiative/nf-binder-design\n\nDATESTAMP=$(date +%Y%m%d_%H%M%S)\n\nnextflow run ${PIPELINE_DIR}/bindcraft.nf \\\n  -c ${PIPELINE_DIR}/conf/platforms/m3.config \\\n  -params-file params.json \\\n  -profile slurm \\\n  -resume \\\n  -with-report results/logs/report_${DATESTAMP}.html \\\n  -with-trace results/logs/trace_${DATESTAMP}.txt\n\n\n\n\nA typical ‘production’ pipeline invocation will run hundreds or thousands of tasks accord many compute nodes. There’s always a chance some will fail. Nextflow does a good job of retrying failed tasks, but after too many failures the pipeline will quit.\nNextflow keeps intermediate files used for resuming a pipeline run in the work directory.\nWhen a process fails, the logs will have a task id like e6/aa312b4 and will indicate a path into the work directory like: work/e6/aa312b4a1da1edaed1ed23d12 - this folder is the working directory for that particular (failed) task.\nThat work/xx/yyyyy directory will contain the files .command.log, .command.err, .command.out (the stdout and stderr logs), .command.sh (the script that was run) amoung other files. You can use these to diagnose what went wrong - often it’s a particular process that needs more memory (RAM) or time assigned via nextflow.config (the scheduler killed the SLURM job), or the process failed due to a bad input file.\n\n\n\nAfter a Nextflow run successfully finishes, the work directory is usually of no use, as it only contains intermediate files, cached to allow resuming. The files you want to preserve are generally in the results directory.\nCarefully … remove the work directory:\nrm ./work -rf",
    "crumbs": [
      "Appendix",
      "Foundational skills: Nextflow crash course"
    ]
  },
  {
    "objectID": "nextflow_crash_course.html#installing-nextflow",
    "href": "nextflow_crash_course.html#installing-nextflow",
    "title": "Foundational skills: Nextflow crash course",
    "section": "",
    "text": "Follow the official Nextflow installation instructions - they are clear, and work. You don’t need sudo to install Nextflow.\n\nTip: Java 17+, a dependency of Nextflow, is available as a module on the M3 HPC cluster as module load java.",
    "crumbs": [
      "Appendix",
      "Foundational skills: Nextflow crash course"
    ]
  },
  {
    "objectID": "nextflow_crash_course.html#downloading-a-pipeline",
    "href": "nextflow_crash_course.html#downloading-a-pipeline",
    "title": "Foundational skills: Nextflow crash course",
    "section": "",
    "text": "Option 1: Download the pipeline code from the Github repository.\ngit clone https://github.com/Australian-Protein-Design-Initiative/nf-binder-design\ncd nf-binder-design\nOption 2: Use Nextflow pull\nnextflow pull Australian-Protein-Design-Initiative/nf-binder-design\n\n# or for a specific version / release\n# nextflow pull -r 0.1.4 Australian-Protein-Design-Initiative/nf-binder-design\n\n# You can see some info about what you just pulled\nnextflow info Australian-Protein-Design-Initiative/nf-binder-design\n\nIn the case of option 2, Nextflow git clones for you into: ~/.nextflow/assets/Australian-Protein-Design-Initiative/nf-binder-design - so you can find things like the default config files in the repository there.",
    "crumbs": [
      "Appendix",
      "Foundational skills: Nextflow crash course"
    ]
  },
  {
    "objectID": "nextflow_crash_course.html#configuring-a-pipeline---nextflow.config",
    "href": "nextflow_crash_course.html#configuring-a-pipeline---nextflow.config",
    "title": "Foundational skills: Nextflow crash course",
    "section": "",
    "text": "Most Nextflow pipelines (especially nf-core flavoured ones), come with sensible pre-configured defaults, but you’ll often need to override or modify some of the settings for your particular computing environment, data and preferences.\nWe will assume here we are running on an HPC cluster using SLURM. Nextflow submits sbatch jobs to the SLURM queue on your behalf, and needs to specify resources and partition settings for each job.\nYou can override defaults by creating a nextflow.config file in the working directory where you run the pipeline. The most common thing you’ll need to do is modify the resources and parition settings for a specific task (‘process’ in Nextflow terminology).\n// nextflow.config\nprocess {\n    withName: BINDCRAFT {\n        // time, cpus, memory (non-GPU) are specified OUTSIDE clusterOptions\n        time = 2.hours\n        memory = '32g'\n        cpus = 16\n\n        // Everything else SLURM sbatch specific goes in clusterOptions\n        // eg, speficying a specific GPU partition\n        clusterOptions = \"--gres=gpu:1 --partition=gpu\"\n    }\n}",
    "crumbs": [
      "Appendix",
      "Foundational skills: Nextflow crash course"
    ]
  },
  {
    "objectID": "nextflow_crash_course.html#running-a-pipeline",
    "href": "nextflow_crash_course.html#running-a-pipeline",
    "title": "Foundational skills: Nextflow crash course",
    "section": "",
    "text": "A wrapper script is a convenient way to record all the commandline arguments you used to run the pipeline and simplify re-running after failures / modifications. We will create a script called run.sh to run the pipeline (and do chmod +x run.sh to make it executable).\n#!/bin/bash\n###\n## run.sh\n###\n\n# We will assume here that you have done `nextflow pull` so the pipeline code is in $HOME/.nextflow/assets/Australian-Protein-Design-Initiative/nf-binder-design\nPIPELINE_DIR=$HOME/.nextflow/assets/Australian-Protein-Design-Initiative/nf-binder-design\n\nDATESTAMP=$(date +%Y%m%d_%H%M%S)\n\nnextflow run ${PIPELINE_DIR}/bindcraft.nf \\\n  -c ${PIPELINE_DIR}/conf/platforms/m3.config \\\n  --input_pdb 'input/PDL1.pdb' \\\n  --outdir results \\\n  --target_chains \"A\" \\\n  --hotspot_res \"A56\" \\\n  --binder_length_range \"65-120\" \\\n  --bindcraft_n_traj 4 \\\n  --bindcraft_batch_size 1 \\\n  -profile slurm \\\n  -resume \\\n  -with-report results/logs/report_${DATESTAMP}.html \\\n  -with-trace results/logs/trace_${DATESTAMP}.txt\nWe include a specific config for the M3 HPC cluster using -c ${PIPELINE_DIR}/conf/platforms/m3.config. If you view this file, you’ll see all the resource and partition settings tuned this particular HPC cluster. You can copy these settings to your own nextflow.config (as above) and override as required.\nWe also include -resume to resume a previous run if it exists - this is benign if it’s the first time you’re running the pipeline, but is important to ensure the pipeline resumes where it left off if you need to restart it in the event of a failure.\n\nNextflow itself is relatively light weight in resource usage, but you can also turn this into an SBATCH script if your HPC adminstrators prefer you to not run it on the login node.\n\n\n\nAn alternative to putting all the “--double-dash” pipeline parameters in the wrapper script is to use a JSON file like:\n{\n    \"input_pdb\": \"input/PDL1.pdb\",\n    \"outdir\": \"results\",\n    \"target_chains\": \"A\",\n    \"hotspot_res\": \"A56\",\n    \"binder_length_range\": \"65-120\",\n    \"bindcraft_n_traj\": 4,\n    \"bindcraft_batch_size\": 1\n}\nAnd run like:\n#!/bin/bash\n###\n## run-with-params.sh\n###\n\n# We will assume here that you have done `nextflow pull` so the pipeline code is in $HOME/.nextflow/assets/Australian-Protein-Design-Initiative/nf-binder-design\nPIPELINE_DIR=$HOME/.nextflow/assets/Australian-Protein-Design-Initiative/nf-binder-design\n\nDATESTAMP=$(date +%Y%m%d_%H%M%S)\n\nnextflow run ${PIPELINE_DIR}/bindcraft.nf \\\n  -c ${PIPELINE_DIR}/conf/platforms/m3.config \\\n  -params-file params.json \\\n  -profile slurm \\\n  -resume \\\n  -with-report results/logs/report_${DATESTAMP}.html \\\n  -with-trace results/logs/trace_${DATESTAMP}.txt",
    "crumbs": [
      "Appendix",
      "Foundational skills: Nextflow crash course"
    ]
  },
  {
    "objectID": "nextflow_crash_course.html#troubleshooting-errors-failures",
    "href": "nextflow_crash_course.html#troubleshooting-errors-failures",
    "title": "Foundational skills: Nextflow crash course",
    "section": "",
    "text": "A typical ‘production’ pipeline invocation will run hundreds or thousands of tasks accord many compute nodes. There’s always a chance some will fail. Nextflow does a good job of retrying failed tasks, but after too many failures the pipeline will quit.\nNextflow keeps intermediate files used for resuming a pipeline run in the work directory.\nWhen a process fails, the logs will have a task id like e6/aa312b4 and will indicate a path into the work directory like: work/e6/aa312b4a1da1edaed1ed23d12 - this folder is the working directory for that particular (failed) task.\nThat work/xx/yyyyy directory will contain the files .command.log, .command.err, .command.out (the stdout and stderr logs), .command.sh (the script that was run) amoung other files. You can use these to diagnose what went wrong - often it’s a particular process that needs more memory (RAM) or time assigned via nextflow.config (the scheduler killed the SLURM job), or the process failed due to a bad input file.",
    "crumbs": [
      "Appendix",
      "Foundational skills: Nextflow crash course"
    ]
  },
  {
    "objectID": "nextflow_crash_course.html#after-the-run",
    "href": "nextflow_crash_course.html#after-the-run",
    "title": "Foundational skills: Nextflow crash course",
    "section": "",
    "text": "After a Nextflow run successfully finishes, the work directory is usually of no use, as it only contains intermediate files, cached to allow resuming. The files you want to preserve are generally in the results directory.\nCarefully … remove the work directory:\nrm ./work -rf",
    "crumbs": [
      "Appendix",
      "Foundational skills: Nextflow crash course"
    ]
  },
  {
    "objectID": "non_m3_snippets.html",
    "href": "non_m3_snippets.html",
    "title": "Apptainer wrapper commands for any system",
    "section": "",
    "text": "If you are running the command from this tutorial on a computer other than the Monash M3 HPC cluster, you won’t nessecarily have the same pre-installed modules (eg module load).\nHere are more detailed snippets that contain the additional Apptainer prefixes required for each command to use the containers available via our container registry on Github.\nThese should run anywhere with Apptainer installed (and a supported NVIDIA GPU).\nYou’ll also need Nextflow for the nf-binder-design examples - see Appendix: Foundational skills: Nextflow crash course.\n\n\n# This prefix `PREFIX_RFD` is here to run RFDiffusion via an Apptainer container. \n# It should work anywhere where Apptainer is installed. You'll need an NVIDIA GPU. \n\n# This version pull the container image from the Github Package Registry - it should work on any system with apptainer installed. The first time it's run there's an initial delay while the container image is downloaded.\nPREFIX_RFD=\"apptainer exec --nv -B $(mktemp -d):/usr/local/lib/python3.10/dist-packages/schedules docker://ghcr.io/australian-protein-design-initiative/containers/rfdiffusion:pytorch2407 \"\n\n# This version uses an Apptainer image pre-downloaded to the workshop scratch space\n#PREFIX_RFD=\"apptainer exec --nv -B $(mktemp -d):/usr/local/lib/python3.10/dist-packages/schedules /scratch2/pd27/shared/containers/ghcr.io-australian-protein-design-initiative-containers-rfdiffusion-pytorch2407.img \"\n\nmkdir -p output/rfdiffusion\n\n$PREFIX_RFD /app/RFdiffusion/scripts/run_inference.py \\\n  inference.input_pdb=input/PDL1.pdb \\\n  'contigmap.contigs=[A18-132/0 65-120]' \\\n  'ppi.hotspot_res=[A56]' \\\n  inference.output_prefix=output/rfdiffusion/pdl1_test \\\n  inference.num_designs=4 \\\n  denoiser.noise_scale_ca=0 \\\n  denoiser.noise_scale_frame=0\n# This version pulls the container image from the Github Package Registry\nPREFIX_PMPNN=\"apptainer exec --nv docker://ghcr.io/australian-protein-design-initiative/containers/proteinmpnn_dl_binder_design:latest \"\n\n# This version uses an Apptainer image pre-downloaded to the workshop scratch space\n#PREFIX_PMPNN=\"apptainer exec --nv /scratch2/pd27/shared/containers/ghcr.io-australian-protein-design-initiative-containers-proteinmpnn_dl_binder_design-latest.img \"\n\nmkdir -p output/proteinmpnn\n\n$PREFIX_PMPNN /app/dl_binder_design/mpnn_fr/dl_interface_design.py \\\n    -pdbdir input/ \\\n    -relax_cycles 0 \\\n    -seqs_per_struct 2 \\\n    -outpdbdir output/proteinmpnn/ \\\n    -omit_AAs C\nPREFIX_AF2IG=\"apptainer exec --nv docker://ghcr.io/australian-protein-design-initiative/containers/af2_initial_guess:nv-cuda12 \"\n\nmkdir -p output/af2_initial_guess/pdbs\n\n$PREFIX_AF2IG python /app/dl_binder_design/af2_initial_guess/predict.py \\\n    -pdbdir output/proteinmpnn \\\n    -outpdbdir output/af2_initial_guess/pdbs/ \\\n    -recycle 3 \\\n    -scorefilename output/af2_initial_guess/pdl1_test.scores.cs\n\n\n\nexport APPTAINERENV_PREPEND_PATH=/opt/conda/envs/BindCraft/bin/\n\n# This version pulls the container image from the Github Package Registry\nPREFIX_BINDCRAFT=\"apptainer exec --cleanenv --env MPLCONFIGDIR=/.matplotlib -B $(mktemp -d):/.matplotlib --nv docker://ghcr.io/australian-protein-design-initiative/containers/bindcraft:05702c4_nv-cuda12 \"\n\n# This version uses an Apptainer image pre-downloaded to the workshop scratch space\n#PREFIX_BINDCRAFT=\"apptainer exec --cleanenv --env MPLCONFIGDIR=/.matplotlib -B $(mktemp -d):/.matplotlib --nv /scratch2/pd27/shared/containers/ghcr.io-australian-protein-design-initiative-containers-bindcraft-05702c4_nv-cuda12.img \"\n\n#    # Ensure that BindCraft finds the correct version of ffmpeg\n#    export PATH=/opt/conda/envs/BindCraft/bin/:\\$PATH\n\n$PREFIX_BINDCRAFT /opt/conda/envs/BindCraft/bin/python \\\n    /app/BindCraft/bindcraft.py \\\n        --settings settings.json \\\n        --filters /app/BindCraft/settings_filters/default_filters.json \\\n        --advanced /app/BindCraft/settings_advanced/default_4stage_multimer.json\n\n# \n#         --filters /app/BindCraft/settings_filters/default_filters.json \\",
    "crumbs": [
      "Appendix",
      "Apptainer wrapper commands for any system"
    ]
  },
  {
    "objectID": "non_m3_snippets.html#rfdiffusion-proteinmpnn-af2-initial-guess",
    "href": "non_m3_snippets.html#rfdiffusion-proteinmpnn-af2-initial-guess",
    "title": "Apptainer wrapper commands for any system",
    "section": "",
    "text": "# This prefix `PREFIX_RFD` is here to run RFDiffusion via an Apptainer container. \n# It should work anywhere where Apptainer is installed. You'll need an NVIDIA GPU. \n\n# This version pull the container image from the Github Package Registry - it should work on any system with apptainer installed. The first time it's run there's an initial delay while the container image is downloaded.\nPREFIX_RFD=\"apptainer exec --nv -B $(mktemp -d):/usr/local/lib/python3.10/dist-packages/schedules docker://ghcr.io/australian-protein-design-initiative/containers/rfdiffusion:pytorch2407 \"\n\n# This version uses an Apptainer image pre-downloaded to the workshop scratch space\n#PREFIX_RFD=\"apptainer exec --nv -B $(mktemp -d):/usr/local/lib/python3.10/dist-packages/schedules /scratch2/pd27/shared/containers/ghcr.io-australian-protein-design-initiative-containers-rfdiffusion-pytorch2407.img \"\n\nmkdir -p output/rfdiffusion\n\n$PREFIX_RFD /app/RFdiffusion/scripts/run_inference.py \\\n  inference.input_pdb=input/PDL1.pdb \\\n  'contigmap.contigs=[A18-132/0 65-120]' \\\n  'ppi.hotspot_res=[A56]' \\\n  inference.output_prefix=output/rfdiffusion/pdl1_test \\\n  inference.num_designs=4 \\\n  denoiser.noise_scale_ca=0 \\\n  denoiser.noise_scale_frame=0\n# This version pulls the container image from the Github Package Registry\nPREFIX_PMPNN=\"apptainer exec --nv docker://ghcr.io/australian-protein-design-initiative/containers/proteinmpnn_dl_binder_design:latest \"\n\n# This version uses an Apptainer image pre-downloaded to the workshop scratch space\n#PREFIX_PMPNN=\"apptainer exec --nv /scratch2/pd27/shared/containers/ghcr.io-australian-protein-design-initiative-containers-proteinmpnn_dl_binder_design-latest.img \"\n\nmkdir -p output/proteinmpnn\n\n$PREFIX_PMPNN /app/dl_binder_design/mpnn_fr/dl_interface_design.py \\\n    -pdbdir input/ \\\n    -relax_cycles 0 \\\n    -seqs_per_struct 2 \\\n    -outpdbdir output/proteinmpnn/ \\\n    -omit_AAs C\nPREFIX_AF2IG=\"apptainer exec --nv docker://ghcr.io/australian-protein-design-initiative/containers/af2_initial_guess:nv-cuda12 \"\n\nmkdir -p output/af2_initial_guess/pdbs\n\n$PREFIX_AF2IG python /app/dl_binder_design/af2_initial_guess/predict.py \\\n    -pdbdir output/proteinmpnn \\\n    -outpdbdir output/af2_initial_guess/pdbs/ \\\n    -recycle 3 \\\n    -scorefilename output/af2_initial_guess/pdl1_test.scores.cs",
    "crumbs": [
      "Appendix",
      "Apptainer wrapper commands for any system"
    ]
  },
  {
    "objectID": "non_m3_snippets.html#bindcraft",
    "href": "non_m3_snippets.html#bindcraft",
    "title": "Apptainer wrapper commands for any system",
    "section": "",
    "text": "export APPTAINERENV_PREPEND_PATH=/opt/conda/envs/BindCraft/bin/\n\n# This version pulls the container image from the Github Package Registry\nPREFIX_BINDCRAFT=\"apptainer exec --cleanenv --env MPLCONFIGDIR=/.matplotlib -B $(mktemp -d):/.matplotlib --nv docker://ghcr.io/australian-protein-design-initiative/containers/bindcraft:05702c4_nv-cuda12 \"\n\n# This version uses an Apptainer image pre-downloaded to the workshop scratch space\n#PREFIX_BINDCRAFT=\"apptainer exec --cleanenv --env MPLCONFIGDIR=/.matplotlib -B $(mktemp -d):/.matplotlib --nv /scratch2/pd27/shared/containers/ghcr.io-australian-protein-design-initiative-containers-bindcraft-05702c4_nv-cuda12.img \"\n\n#    # Ensure that BindCraft finds the correct version of ffmpeg\n#    export PATH=/opt/conda/envs/BindCraft/bin/:\\$PATH\n\n$PREFIX_BINDCRAFT /opt/conda/envs/BindCraft/bin/python \\\n    /app/BindCraft/bindcraft.py \\\n        --settings settings.json \\\n        --filters /app/BindCraft/settings_filters/default_filters.json \\\n        --advanced /app/BindCraft/settings_advanced/default_4stage_multimer.json\n\n# \n#         --filters /app/BindCraft/settings_filters/default_filters.json \\",
    "crumbs": [
      "Appendix",
      "Apptainer wrapper commands for any system"
    ]
  },
  {
    "objectID": "hardware_and_software.html",
    "href": "hardware_and_software.html",
    "title": "Hardware and software requirements",
    "section": "",
    "text": "Or, “how can I run this at home ?”\n\n\nWhat kind of hardware do I need ?\n\nTODO: GPUs, the more the better. Local workstation example, HPC example, cloud example. Longer proteins require more VRAM.",
    "crumbs": [
      "Appendix",
      "Hardware and software requirements"
    ]
  },
  {
    "objectID": "hardware_and_software.html#compute-resources",
    "href": "hardware_and_software.html#compute-resources",
    "title": "Hardware and software requirements",
    "section": "",
    "text": "What kind of hardware do I need ?\n\nTODO: GPUs, the more the better. Local workstation example, HPC example, cloud example. Longer proteins require more VRAM.",
    "crumbs": [
      "Appendix",
      "Hardware and software requirements"
    ]
  },
  {
    "objectID": "hardware_and_software.html#licensing",
    "href": "hardware_and_software.html#licensing",
    "title": "Hardware and software requirements",
    "section": "Licensing",
    "text": "Licensing\nThe foundation of these tools are available under under permissive open source licenses and can be used freely for non-commercial use. However, NOTE that PyRosetta, a component of both RFDiffusion and BindCraft, requires a license from the University of Washington for commercial use.",
    "crumbs": [
      "Appendix",
      "Hardware and software requirements"
    ]
  },
  {
    "objectID": "hardware_and_software.html#installation",
    "href": "hardware_and_software.html#installation",
    "title": "Hardware and software requirements",
    "section": "Installation",
    "text": "Installation\n\n\n\n\n\n\nWarning\n\n\n\nFor this workshop, you don’t need to install anything. We’ve set things up to run in Apptainer containers that are already downloaded.\nInstalling these packges typically takes hours, and troubleshooting research software installation is a topic for an entirely different wokshop.\n\n\nYou’ll want a Linux based operating system. You do not nessecarily need admin / sudo permissions.\nMethods, roughly in order of preference:",
    "crumbs": [
      "Appendix",
      "Hardware and software requirements"
    ]
  },
  {
    "objectID": "hardware_and_software.html#engage-your-local-hpc-or-research-cloud-admins-to-help-create-a-shared-installation-everyone-can-use.",
    "href": "hardware_and_software.html#engage-your-local-hpc-or-research-cloud-admins-to-help-create-a-shared-installation-everyone-can-use.",
    "title": "Hardware and software requirements",
    "section": "1. Engage your local HPC or research cloud admins to help create a shared installation everyone can use.",
    "text": "1. Engage your local HPC or research cloud admins to help create a shared installation everyone can use.\nThey are often experienced in troubleshooting installation and dependency issues that can be specific to the systems they maintain.",
    "crumbs": [
      "Appendix",
      "Hardware and software requirements"
    ]
  },
  {
    "objectID": "hardware_and_software.html#use-a-container",
    "href": "hardware_and_software.html#use-a-container",
    "title": "Hardware and software requirements",
    "section": "2. Use a container",
    "text": "2. Use a container\nApptainer (formerly known as Singularity) simplifies deployment of software by bundling up the software and its dependencies, including a simple Linux system image, into a single container.\nDocker is another popular alternative, but isn’t usually available on HPC systems due to security constraints.\nApptainer can run Docker images, so you rarely need Docker to run research software.\nAll the container images used in this workshop are available here and the Dockerfile recipes used to build them are available here.",
    "crumbs": [
      "Appendix",
      "Hardware and software requirements"
    ]
  },
  {
    "objectID": "hardware_and_software.html#use-a-pipeline",
    "href": "hardware_and_software.html#use-a-pipeline",
    "title": "Hardware and software requirements",
    "section": "3. Use a pipeline",
    "text": "3. Use a pipeline\nA Nextflow pipeline like nf-binder-design can help manage running all the steps in an RFdiffusion - ProteinMPNN - Alphafold2 (or BindCraft) workflow.\nThe best pipelines typically use publically available Apptainer containers by default, so you don’t need to think about installing each of the tools yourself.",
    "crumbs": [
      "Appendix",
      "Hardware and software requirements"
    ]
  },
  {
    "objectID": "hardware_and_software.html#install-yourself",
    "href": "hardware_and_software.html#install-yourself",
    "title": "Hardware and software requirements",
    "section": "4. Install yourself",
    "text": "4. Install yourself\nFollow the instrucions at https://github.com/RosettaCommons/RFdiffusion and https://github.com/martinpacesa/BindCraft - the installation steps are well documented, but don’t always work perfectly in every environment without some troubleshooting.\n(or see step 1 above)",
    "crumbs": [
      "Appendix",
      "Hardware and software requirements"
    ]
  },
  {
    "objectID": "bindcraft_scoring.html",
    "href": "bindcraft_scoring.html",
    "title": "BindCraft : analysing a full design run",
    "section": "",
    "text": "We’ve run 400 BindCraft trajectories for PDL1 using nf-binder-design -the results are in /scratch2/pd27/shared/examples/nfbd/pdl1-bindcraft - this reflects a more realistic number of trajectories for a ‘production run’.\n\n\n\n\n\n\nCautionChallenge - viewing the BindCraft results\n\n\n\nView the table final_design_stats.csv - how many accepted designs do we have ? What is the acceptance rate ?\nWhat do the designs with almost the same name, but different _mpnn{n} suffixes have in common ?\nView a the the PDB files in Accepted/. Examine the target-binder interface of some designs with high and low ipTM scores.\n\n\nBindCraft outputs many scores, but for ranking designs we’d typically focus on:\n\nAverage_i_pTM - the average ipTM across each Alphafold2 model for this complex\n\n\nNote that since fairly stringent filters have already been applied, any of the Accepted designs is considered to have a good chance of binding.\n\nHere are all the scores you’ll find in the final_design_stats.csv file. The 1_, 2_, 3_, etc scores are for each different Alphafold2 model:\nRank,Design,Protocol,Length,Seed,Helicity,Target_Hotspot,Sequence,InterfaceResidues,\n\nMPNN_score,MPNN_seq_recovery,\n\nAverage_pLDDT,          1_pLDDT,2_pLDDT,3_pLDDT,4_pLDDT,5_pLDDT,\nAverage_pTM,            1_pTM,2_pTM,3_pTM,4_pTM,5_pTM,\nAverage_i_pTM,          1_i_pTM,2_i_pTM,3_i_pTM,4_i_pTM,5_i_pTM,\nAverage_pAE,            1_pAE,2_pAE,3_pAE,4_pAE,5_pAE,\nAverage_i_pAE,          1_i_pAE,2_i_pAE,3_i_pAE,4_i_pAE,5_i_pAE,\nAverage_i_pLDDT,        1_i_pLDDT,2_i_pLDDT,3_i_pLDDT,4_i_pLDDT,5_i_pLDDT,\nAverage_ss_pLDDT,       1_ss_pLDDT,2_ss_pLDDT,3_ss_pLDDT,4_ss_pLDDT,5_ss_pLDDT,\n\nAverage_Unrelaxed_Clashes,  1_Unrelaxed_Clashes,2_Unrelaxed_Clashes,3_Unrelaxed_Clashes,4_Unrelaxed_Clashes,5_Unrelaxed_Clashes,\nAverage_Relaxed_Clashes,    1_Relaxed_Clashes,2_Relaxed_Clashes,3_Relaxed_Clashes,4_Relaxed_Clashes,5_Relaxed_Clashes,\nAverage_Binder_Energy_Score,    1_Binder_Energy_Score,2_Binder_Energy_Score,3_Binder_Energy_Score,4_Binder_Energy_Score,5_Binder_Energy_Score,\nAverage_Surface_Hydrophobicity, 1_Surface_Hydrophobicity,2_Surface_Hydrophobicity,3_Surface_Hydrophobicity,4_Surface_Hydrophobicity,5_Surface_Hydrophobicity,\nAverage_ShapeComplementarity,   1_ShapeComplementarity,2_ShapeComplementarity,3_ShapeComplementarity,4_ShapeComplementarity,5_ShapeComplementarity,\nAverage_PackStat,       1_PackStat,2_PackStat,3_PackStat,4_PackStat,5_PackStat,\nAverage_dG,         1_dG,2_dG,3_dG,4_dG,5_dG,\nAverage_dSASA,          1_dSASA,2_dSASA,3_dSASA,4_dSASA,5_dSASA,\nAverage_dG/dSASA,       1_dG/dSASA,2_dG/dSASA,3_dG/dSASA,4_dG/dSASA,5_dG/dSASA,\nAverage_Interface_SASA_%,   1_Interface_SASA_%,2_Interface_SASA_%,3_Interface_SASA_%,4_Interface_SASA_%,5_Interface_SASA_%,\nAverage_Interface_Hydrophobicity,   1_Interface_Hydrophobicity,2_Interface_Hydrophobicity,3_Interface_Hydrophobicity,4_Interface_Hydrophobicity,5_Interface_Hydrophobicity,\nAverage_n_InterfaceResidues,    1_n_InterfaceResidues,2_n_InterfaceResidues,3_n_InterfaceResidues,4_n_InterfaceResidues,5_n_InterfaceResidues,\nAverage_n_InterfaceHbonds,  1_n_InterfaceHbonds,2_n_InterfaceHbonds,3_n_InterfaceHbonds,4_n_InterfaceHbonds,5_n_InterfaceHbonds,\nAverage_InterfaceHbondsPercentage,  1_InterfaceHbondsPercentage,2_InterfaceHbondsPercentage,3_InterfaceHbondsPercentage,4_InterfaceHbondsPercentage,5_InterfaceHbondsPercentage,\nAverage_n_InterfaceUnsatHbonds, 1_n_InterfaceUnsatHbonds,2_n_InterfaceUnsatHbonds,3_n_InterfaceUnsatHbonds,4_n_InterfaceUnsatHbonds,5_n_InterfaceUnsatHbonds,\nAverage_InterfaceUnsatHbondsPercentage, 1_InterfaceUnsatHbondsPercentage,2_InterfaceUnsatHbondsPercentage,3_InterfaceUnsatHbondsPercentage,4_InterfaceUnsatHbondsPercentage,5_InterfaceUnsatHbondsPercentage,\n\nAverage_Interface_Helix%,       1_Interface_Helix%,2_Interface_Helix%,3_Interface_Helix%,4_Interface_Helix%,5_Interface_Helix%,\nAverage_Interface_BetaSheet%,       1_Interface_BetaSheet%,2_Interface_BetaSheet%,3_Interface_BetaSheet%,4_Interface_BetaSheet%,5_Interface_BetaSheet%,\nAverage_Interface_Loop%,        1_Interface_Loop%,2_Interface_Loop%,3_Interface_Loop%,4_Interface_Loop%,5_Interface_Loop%,\nAverage_Binder_Helix%,          1_Binder_Helix%,2_Binder_Helix%,3_Binder_Helix%,4_Binder_Helix%,5_Binder_Helix%,\nAverage_Binder_BetaSheet%,      1_Binder_BetaSheet%,2_Binder_BetaSheet%,3_Binder_BetaSheet%,4_Binder_BetaSheet%,5_Binder_BetaSheet%,\nAverage_Binder_Loop%,           1_Binder_Loop%,2_Binder_Loop%,3_Binder_Loop%,4_Binder_Loop%,5_Binder_Loop%,\n\nAverage_InterfaceAAs,       1_InterfaceAAs,2_InterfaceAAs,3_InterfaceAAs,4_InterfaceAAs,5_InterfaceAAs,\n\nAverage_Hotspot_RMSD,       1_Hotspot_RMSD,2_Hotspot_RMSD,3_Hotspot_RMSD,4_Hotspot_RMSD,5_Hotspot_RMSD,\nAverage_Target_RMSD,        1_Target_RMSD,2_Target_RMSD,3_Target_RMSD,4_Target_RMSD,5_Target_RMSD,\nAverage_Binder_pLDDT,       1_Binder_pLDDT,2_Binder_pLDDT,3_Binder_pLDDT,4_Binder_pLDDT,5_Binder_pLDDT,\nAverage_Binder_pTM,     1_Binder_pTM,2_Binder_pTM,3_Binder_pTM,4_Binder_pTM,5_Binder_pTM,\nAverage_Binder_pAE,     1_Binder_pAE,2_Binder_pAE,3_Binder_pAE,4_Binder_pAE,5_Binder_pAE,\nAverage_Binder_RMSD,        1_Binder_RMSD,2_Binder_RMSD,3_Binder_RMSD,4_Binder_RMSD,5_Binder_RMSD,\n\nDesignTime,Notes,TargetSettings,Filters,AdvancedSettings\n\nDefault filters\nDesigns that satisfy these critera are kept as ‘Accepted’:\n\nAlphaFold2 Metrics\n\nAverage_pLDDT &gt; 0.8\nAverage_pTM &gt; 0.55\nAverage_i_pTM &gt; 0.5\nAverage_i_pAE &lt; 0.35\n\nRosetta Metrics\n\nAverage_Binder_Energy_Score &lt; 0\nAverage_Surface_Hydrophobicity &lt; 0.35\nAverage_ShapeComplementarity &gt; 0.6\nAverage_dG &lt; 0\nAverage_dSASA &gt; 1\nAverage_n_InterfaceResidues &gt; 7\nAverage_n_InterfaceHbonds &gt; 3\nAverage_n_InterfaceUnsatHbonds &lt; 4\nAverage_InterfaceAAs: K &lt; 3\nAverage_InterfaceAAs: M &lt; 3\n\nStructural Metrics\n\nAverage_Binder_Loop% &lt; 90\nAverage_Hotspot_RMSD &lt; 6\nAverage_Binder_pLDDT &gt; 0.8\nAverage_Binder_RMSD &lt; 3.5\n\n\n\n\nOptimizing BindCraft settings\nIt can take ‘many shots’ in silico to get a ‘one shot’ binder in the wet lab.\nHere’s a figure from the BindCraft paper that gives some insight:\n’\nEach target required different numbers of trajectories, with a wide range in in silico acceptance rates, to achieve the suggested “100 accepted designs to select 20 for assay” benchmark. Part f shows the impact of binder length range alone on in silico success rates.\nWhat we don’t see here is the trajactories run testing alternative target structures, trimmings and hotspot combinations - expect to run many more trajectories than you’ll ultimately require for your final ‘production’ run.\nThe two key parameters you should adjust to get more ‘accepted’ designs are:\n\nthe target structure (different models, different trimmings)\nthe hotspots\n\nModifying the default filters or advanced settings should typically be approached with extreme caution - not all ‘advanced’ settings have been systematically tested and may reduce the success rates reported in the BindCraft paper. Caveat emptor\n\n\n\n\nReuseCC BY 4.0",
    "crumbs": [
      "BindCraft",
      "BindCraft : analysing a full design run"
    ]
  },
  {
    "objectID": "bindcraft_background.html",
    "href": "bindcraft_background.html",
    "title": "BindCraft Background",
    "section": "",
    "text": "Pacesa et al, Nature, 2025 - One-shot design of functional protein binders with BindCraft\n\n\n\nFigure 1a from Pacesa el al 2025 (https://doi.org/10.1038/s41586-025-09429-6) - a high level overview of the BindCraft design pipeline\n\n\nHallucination with the Alphafold2 model as implemented by ColabDesign.\nThe trajectory is split into four stages, where in each stage the probability distribution of the sequence at each position predicted by the Alphafold2 model is made increasingly discrete.\nie, we go from ‘fuzzy’ this many possible residues at a position, to fixing on the highest probability residue.\n\n\n\nFrom Martin Pacesa and Lennart Nickel’s presentation https://www.youtube.com/watch?v=u5yijcBsonw\n\n\nThe final ‘semi-greedy’ stage tests the impact of randomly mutating a small fraction of positions (based on a PSSM derived from the sequence logits)",
    "crumbs": [
      "BindCraft",
      "BindCraft Background"
    ]
  },
  {
    "objectID": "bindcraft_background.html#bindcraft-methodology-overview",
    "href": "bindcraft_background.html#bindcraft-methodology-overview",
    "title": "BindCraft Background",
    "section": "",
    "text": "Pacesa et al, Nature, 2025 - One-shot design of functional protein binders with BindCraft\n\n\n\nFigure 1a from Pacesa el al 2025 (https://doi.org/10.1038/s41586-025-09429-6) - a high level overview of the BindCraft design pipeline\n\n\nHallucination with the Alphafold2 model as implemented by ColabDesign.\nThe trajectory is split into four stages, where in each stage the probability distribution of the sequence at each position predicted by the Alphafold2 model is made increasingly discrete.\nie, we go from ‘fuzzy’ this many possible residues at a position, to fixing on the highest probability residue.\n\n\n\nFrom Martin Pacesa and Lennart Nickel’s presentation https://www.youtube.com/watch?v=u5yijcBsonw\n\n\nThe final ‘semi-greedy’ stage tests the impact of randomly mutating a small fraction of positions (based on a PSSM derived from the sequence logits)",
    "crumbs": [
      "BindCraft",
      "BindCraft Background"
    ]
  },
  {
    "objectID": "bindcraft_background.html#the-bindcraft-loss-function",
    "href": "bindcraft_background.html#the-bindcraft-loss-function",
    "title": "BindCraft Background",
    "section": "The BindCraft loss function",
    "text": "The BindCraft loss function\nIt’s instructive to look at what goes into the BindCraft loss function that guides the trajectory and generates the initial design. We have weighted terms that drive the confidence of the binder and confidence of the interface, as well as encouraging more non-helical secondary structure and a more compact radius of gyration.\n\\[\\begin{align}\nℒ &= 0.1⋅(1−pLDDT) \\nonumber \\\\\n  &\\quad + 0.05⋅ipTM \\nonumber \\\\\n  &\\quad + 0.4⋅pAE_{binder} \\nonumber \\\\\n  &\\quad + 0.1⋅ipAE_{interchain} \\nonumber \\\\\n  &\\quad + 1.0⋅hotspot\\_contact_{loss} \\nonumber \\\\\n  &\\quad + 0.3⋅radius_{gyr} \\nonumber \\\\\n  &\\quad - 0.3⋅helicity_{loss}\n\\end{align}\\]",
    "crumbs": [
      "BindCraft",
      "BindCraft Background"
    ]
  },
  {
    "objectID": "rfdiffusion_exercise.html",
    "href": "rfdiffusion_exercise.html",
    "title": "RFdiffusion Exercise",
    "section": "",
    "text": "We will start with the ‘manual’ way, running each of the steps in the RFdiffusion -&gt; ProteinMPNN -&gt; Alphafold2 initial guess workflow individually.\nThen, we will run the nf-binder-design workflow that combines these steps into a more streamlined pipeline to better suit ‘production’ use on high-performance computing.\n\n\n    \n    \n    \n(press the spanner icon to see the sequence, )\nHere’s version of the PDL1 domain we cropped in the previous exercise: PDL1.pdb\nOn your server, let’s create a directory for our RFDiffusion work and upload this PDB file to input/PDL1.pdb:\n# Start by creating a directory where we will work - this may be your home directory,\n# but in this case each participant should create a specifc path with their username in the workshop scratch space\nmkdir -p /scratch2/pd27/users/${USER}\ncd /scratch2/pd27/users/${USER}\n\nmkdir -p exercises/rfd/input\ncd exercises/rfd\nUpload your trimmed PDL1 PDB file to /scratch2/pd27/users/${USER}/exercises/rfd/input/PDL1.pdb (using rsync, scp or your preferred method).\nIf you’d like to use a pre-prepared PDL1.pdb rather than your own, run:\nwget -O input/PDL1.pdb https://australian-protein-design-initiative.github.io/binder-design-workshop/exercises/rfd/input/PDL1.pdb\n\n\n\nRFdiffusion is a general tool for hallucinating protein structures - not only de novo binder design.\nHere, we are going to run RFdiffusion with parameters specific for generating a small de novo binder chains, hopefully with good shape complementarity to our target and near our hotspots.\nLet’s start by running the command, and while things are running we can break down what each part does:\n# Load the RFdiffusion module that is pre-installed on the M3 HPC cluster\n# This puts the RFdiffusion script `run_inference.py` on your PATH\n#\nmodule load rfdiffusion/.b44206a\n\nmkdir -p output/rfdiffusion\n\nrun_inference.py \\\n  inference.input_pdb=input/PDL1.pdb \\\n  'contigmap.contigs=[A18-132/0 65-120]' \\\n  'ppi.hotspot_res=[A56]' \\\n  inference.output_prefix=output/rfdiffusion/pdl1_test \\\n  inference.num_designs=4 \\\n  denoiser.noise_scale_ca=0 \\\n  denoiser.noise_scale_frame=0\nOn a T4 GPU, this takes about ~8 minutes (~2 minutes per design).\n\nNote that this version of the workshop is tailored for the M3 HPC cluster where we’ve pre-installed each tool as a module. If you are running this on a different system, you will need to adapt these commands to use the Apptainer containers less transparently - see Appendix: Running the Apptainer containers on any system.\n\n\n\nmodule load nvitop/1.3.2\n# (nvitop is also pip-installable)\n\nnvitop\n\n# a more bare-bones version that is usually always installed when an NVIDIA GPU is present is\n# nvidia-smi -l 10\nOpen a second terminal on your compute node where RFdiffusion is running and watch the GPU utilization with nvitop.\n\n\n\n\ninference.input_pdb: our target PDB file- this should contain (possibly cropped) target coordinates\ncontigmap.contigs: define the regions of the target we want to include (A18-132/0), and a length range for the new chain to generate (65-120)\nppi.hotspot_res: our hotspot residues\ninference.output_prefix: the prefix for the output files (can be {directory}/{filename} prefix)\ninference.num_designs: the number of designs (trajectories) to generate - we generate just a small number here - normally this might be 1000 or more\ndenoiser.noise_scale_ca and denoiser.noise_scale_frame: the noise scale for the translations and rotations - set to zero, since this is reported to improve the quality of the models as the expense of diversity (0.5 might also be a reasonable value)\n\n\n\nThe contig syntax is a way of specifying existing residues in the target to include, and new residues / chains to add by hallucination.\nA18-132 says ‘include the existing chain A, residues 18-132’ - we could exclude an N-terminal region like A27-132 - this would be equivalent to deleting those ATOM records.\nThe /0 at the end of A18-132/0 specifies a chain break. This is important - if you exclude it, the new generated residues will be fused to the C-terminal end of your target !\nIf we had a second chain B in the target, we might have something like: A18-132/0 B33-148/0 65-120\nIf we had a missing loop in our target spanning residues 73-83, we would need: A18-72/A84-132/0 65-120 (RFdiffusion will complain with an error if you include residues in a contig that don’t exist)\nIf a segment does not have a chain ID specfied, like 65-120, this is treated as a new chain to hallicinate, with a lower and upper length range.\n\n\n\n\n\n\nCautionChallenge - defining contigs\n\n\n\nIf we used the full original 3BIK.pdb PDB file instead of manually trimming our coordinates in ChimeraX/Pymol/Vim, what contig expression could we use to ‘virtually’ trim to our domain of interest ?\nHow would we generate binders to our PDL1 domain that are exactly 100 residues long ?\n\n\nYou can see the full list of configuration options for RFdiffusion with:\nrun_inference.py --help\n… most should usually be left as the defaults.\nSome, like inference.ckpt_override_path are automatically set to select the correct model weights based on other config options in use.\nFor binder design, manually setting inference.ckpt_override_path=/models/rfdiffusion/Complex_beta_ckpt.pt can be useful to increase the beta-strand content of designs (this model is reportedly less well tested - YMMV !).\n\n\n/models/rfdiffusion/ corresponds to the path where your RFdiffusion model weights were downloaded to - /models/rfdiffusion/ is a valid path in the context of the containers (and M3 module) we are using here but may be different for other installations of RFdiffusion.\n\n\n\n\n\n\n\n\n\n\n\n\nTODO\n\n# Load the dl_binder_design (ProteinMPNN) module that is pre-installed on the M3 HPC cluster\n# This puts the script `dl_interface_design.py` (from https://github.com/nrbennet/dl_binder_design/blob/main/mpnn_fr/dl_interface_design.py) on your PATH\n#\nmodule load dl_binder_design/.cafa385\n\nmkdir -p output/proteinmpnn\n\ndl_interface_design.py \\\n    -pdbdir output/rfdiffusion/ \\\n    -relax_cycles 0 \\\n    -seqs_per_struct 2 \\\n    -outpdbdir output/proteinmpnn/ \\\n    -omit_AAs C\nOther useful options:\n\n-checkpoint_path\n-temperature\n-augment_eps\n\nProteinMPNN detects the GPU on our compute node, but it isn’t appreciably faster on GPU - if running in a separate job, no need to waste a GPU for this.\n\n\n\nOnce sequences have been generated for the backbone design via inverse folding, we want to predict more accurately if this binder sequence is likely to fold into the correct structure.\n\nTODO\n\n# Load the dl_binder_design (Alphafold2 initial guess) module that is pre-installed on the M3 HPC cluster\n# This puts the script `predict.py`(from https://github.com/nrbennet/dl_binder_design/blob/main/af2_initial_guess/predict.py) on your PATH\n#\nmodule load dl_binder_design/.cafa385\n\nmkdir -p output/af2_initial_guess/pdbs\n\npredict.py \\\n    -pdbdir output/proteinmpnn \\\n    -outpdbdir output/af2_initial_guess/pdbs/ \\\n    -recycle 3 \\\n    -scorefilename output/af2_initial_guess/pdl1_test.scores.cs\nOn a T4 GPU, each AF2 initial guess structure for these complexes takes ~1.3 mins each (~10 min total), on average.",
    "crumbs": [
      "RFdiffusion (& ProteinMPNN)",
      "RFdiffusion Exercise"
    ]
  },
  {
    "objectID": "rfdiffusion_exercise.html#the-target",
    "href": "rfdiffusion_exercise.html#the-target",
    "title": "RFdiffusion Exercise",
    "section": "",
    "text": "(press the spanner icon to see the sequence, )\nHere’s version of the PDL1 domain we cropped in the previous exercise: PDL1.pdb\nOn your server, let’s create a directory for our RFDiffusion work and upload this PDB file to input/PDL1.pdb:\n# Start by creating a directory where we will work - this may be your home directory,\n# but in this case each participant should create a specifc path with their username in the workshop scratch space\nmkdir -p /scratch2/pd27/users/${USER}\ncd /scratch2/pd27/users/${USER}\n\nmkdir -p exercises/rfd/input\ncd exercises/rfd\nUpload your trimmed PDL1 PDB file to /scratch2/pd27/users/${USER}/exercises/rfd/input/PDL1.pdb (using rsync, scp or your preferred method).\nIf you’d like to use a pre-prepared PDL1.pdb rather than your own, run:\nwget -O input/PDL1.pdb https://australian-protein-design-initiative.github.io/binder-design-workshop/exercises/rfd/input/PDL1.pdb",
    "crumbs": [
      "RFdiffusion (& ProteinMPNN)",
      "RFdiffusion Exercise"
    ]
  },
  {
    "objectID": "rfdiffusion_exercise.html#running-rfdiffusion-binder-design",
    "href": "rfdiffusion_exercise.html#running-rfdiffusion-binder-design",
    "title": "RFdiffusion Exercise",
    "section": "",
    "text": "RFdiffusion is a general tool for hallucinating protein structures - not only de novo binder design.\nHere, we are going to run RFdiffusion with parameters specific for generating a small de novo binder chains, hopefully with good shape complementarity to our target and near our hotspots.\nLet’s start by running the command, and while things are running we can break down what each part does:\n# Load the RFdiffusion module that is pre-installed on the M3 HPC cluster\n# This puts the RFdiffusion script `run_inference.py` on your PATH\n#\nmodule load rfdiffusion/.b44206a\n\nmkdir -p output/rfdiffusion\n\nrun_inference.py \\\n  inference.input_pdb=input/PDL1.pdb \\\n  'contigmap.contigs=[A18-132/0 65-120]' \\\n  'ppi.hotspot_res=[A56]' \\\n  inference.output_prefix=output/rfdiffusion/pdl1_test \\\n  inference.num_designs=4 \\\n  denoiser.noise_scale_ca=0 \\\n  denoiser.noise_scale_frame=0\nOn a T4 GPU, this takes about ~8 minutes (~2 minutes per design).\n\nNote that this version of the workshop is tailored for the M3 HPC cluster where we’ve pre-installed each tool as a module. If you are running this on a different system, you will need to adapt these commands to use the Apptainer containers less transparently - see Appendix: Running the Apptainer containers on any system.\n\n\n\nmodule load nvitop/1.3.2\n# (nvitop is also pip-installable)\n\nnvitop\n\n# a more bare-bones version that is usually always installed when an NVIDIA GPU is present is\n# nvidia-smi -l 10\nOpen a second terminal on your compute node where RFdiffusion is running and watch the GPU utilization with nvitop.\n\n\n\n\ninference.input_pdb: our target PDB file- this should contain (possibly cropped) target coordinates\ncontigmap.contigs: define the regions of the target we want to include (A18-132/0), and a length range for the new chain to generate (65-120)\nppi.hotspot_res: our hotspot residues\ninference.output_prefix: the prefix for the output files (can be {directory}/{filename} prefix)\ninference.num_designs: the number of designs (trajectories) to generate - we generate just a small number here - normally this might be 1000 or more\ndenoiser.noise_scale_ca and denoiser.noise_scale_frame: the noise scale for the translations and rotations - set to zero, since this is reported to improve the quality of the models as the expense of diversity (0.5 might also be a reasonable value)\n\n\n\nThe contig syntax is a way of specifying existing residues in the target to include, and new residues / chains to add by hallucination.\nA18-132 says ‘include the existing chain A, residues 18-132’ - we could exclude an N-terminal region like A27-132 - this would be equivalent to deleting those ATOM records.\nThe /0 at the end of A18-132/0 specifies a chain break. This is important - if you exclude it, the new generated residues will be fused to the C-terminal end of your target !\nIf we had a second chain B in the target, we might have something like: A18-132/0 B33-148/0 65-120\nIf we had a missing loop in our target spanning residues 73-83, we would need: A18-72/A84-132/0 65-120 (RFdiffusion will complain with an error if you include residues in a contig that don’t exist)\nIf a segment does not have a chain ID specfied, like 65-120, this is treated as a new chain to hallicinate, with a lower and upper length range.\n\n\n\n\n\n\nCautionChallenge - defining contigs\n\n\n\nIf we used the full original 3BIK.pdb PDB file instead of manually trimming our coordinates in ChimeraX/Pymol/Vim, what contig expression could we use to ‘virtually’ trim to our domain of interest ?\nHow would we generate binders to our PDL1 domain that are exactly 100 residues long ?\n\n\nYou can see the full list of configuration options for RFdiffusion with:\nrun_inference.py --help\n… most should usually be left as the defaults.\nSome, like inference.ckpt_override_path are automatically set to select the correct model weights based on other config options in use.\nFor binder design, manually setting inference.ckpt_override_path=/models/rfdiffusion/Complex_beta_ckpt.pt can be useful to increase the beta-strand content of designs (this model is reportedly less well tested - YMMV !).\n\n\n/models/rfdiffusion/ corresponds to the path where your RFdiffusion model weights were downloaded to - /models/rfdiffusion/ is a valid path in the context of the containers (and M3 module) we are using here but may be different for other installations of RFdiffusion.",
    "crumbs": [
      "RFdiffusion (& ProteinMPNN)",
      "RFdiffusion Exercise"
    ]
  },
  {
    "objectID": "rfdiffusion_exercise.html#proteinmpnn-inverse-folding",
    "href": "rfdiffusion_exercise.html#proteinmpnn-inverse-folding",
    "title": "RFdiffusion Exercise",
    "section": "",
    "text": "TODO\n\n# Load the dl_binder_design (ProteinMPNN) module that is pre-installed on the M3 HPC cluster\n# This puts the script `dl_interface_design.py` (from https://github.com/nrbennet/dl_binder_design/blob/main/mpnn_fr/dl_interface_design.py) on your PATH\n#\nmodule load dl_binder_design/.cafa385\n\nmkdir -p output/proteinmpnn\n\ndl_interface_design.py \\\n    -pdbdir output/rfdiffusion/ \\\n    -relax_cycles 0 \\\n    -seqs_per_struct 2 \\\n    -outpdbdir output/proteinmpnn/ \\\n    -omit_AAs C\nOther useful options:\n\n-checkpoint_path\n-temperature\n-augment_eps\n\nProteinMPNN detects the GPU on our compute node, but it isn’t appreciably faster on GPU - if running in a separate job, no need to waste a GPU for this.",
    "crumbs": [
      "RFdiffusion (& ProteinMPNN)",
      "RFdiffusion Exercise"
    ]
  },
  {
    "objectID": "rfdiffusion_exercise.html#alphafold2-initial-guess---scoring-by-prediction",
    "href": "rfdiffusion_exercise.html#alphafold2-initial-guess---scoring-by-prediction",
    "title": "RFdiffusion Exercise",
    "section": "",
    "text": "Once sequences have been generated for the backbone design via inverse folding, we want to predict more accurately if this binder sequence is likely to fold into the correct structure.\n\nTODO\n\n# Load the dl_binder_design (Alphafold2 initial guess) module that is pre-installed on the M3 HPC cluster\n# This puts the script `predict.py`(from https://github.com/nrbennet/dl_binder_design/blob/main/af2_initial_guess/predict.py) on your PATH\n#\nmodule load dl_binder_design/.cafa385\n\nmkdir -p output/af2_initial_guess/pdbs\n\npredict.py \\\n    -pdbdir output/proteinmpnn \\\n    -outpdbdir output/af2_initial_guess/pdbs/ \\\n    -recycle 3 \\\n    -scorefilename output/af2_initial_guess/pdl1_test.scores.cs\nOn a T4 GPU, each AF2 initial guess structure for these complexes takes ~1.3 mins each (~10 min total), on average.",
    "crumbs": [
      "RFdiffusion (& ProteinMPNN)",
      "RFdiffusion Exercise"
    ]
  },
  {
    "objectID": "rfdiffusion_exercise.html#de-novo-binders-against-pdl1-with-nf-binder-design",
    "href": "rfdiffusion_exercise.html#de-novo-binders-against-pdl1-with-nf-binder-design",
    "title": "RFdiffusion Exercise",
    "section": "De novo binders against PDL1 with nf-binder-design",
    "text": "De novo binders against PDL1 with nf-binder-design\nHere’s our example above, using the nf-binder-design RFdiffusion workflow.\nFirst create a directory for our work and copy the PDL1 PDB file to it:\nmkdir -p /scratch2/pd27/users/${USER}/exercises/rfd-nfbd/input\ncd /scratch2/pd27/users/${USER}/exercises/rfd-nfbd\ncp ../rfd/input/PDL1.pdb input/\nNow we are ready to run the pipeline:\n# Load the nextflow module that is pre-installed on the M3 HPC cluster\n# Any recent version from the last ~12 months should work\nmodule load nextflow/24.04.3 \n\n# Nextflow automatically downloads containers for the software automatically.\n# To save some time, the containers for the pipeline have been pre-cached for the workshop.\n# We set these environment variables to point to the Apptainer cache location.\n# Outside the workshop, this would be somewhere on your scratch space \n# (don't use your /home directory - it will go over quota !)\n# You might add exports like this to your ~/.bashrc\nexport NXF_APPTAINER_CACHEDIR=/scratch2/pd27/shared/containers\nexport APPTAINER_CACHEDIR=$NXF_APPTAINER_CACHEDIR\nunset NXF_SINGULARITY_CACHEDIR\n\nnextflow run Australian-Protein-Design-Initiative/nf-binder-design \\\n  --input_pdb 'input/*.pdb' \\\n  --outdir results \\\n  --contigs \"[A18-132/0 65-120]\" \\\n  --hotspot_res \"A56\" \\\n  --rfd_n_designs=4 \\\n  --rfd_batch_size=1 \\\n  --pmpnn_seqs_per_struct=2 \\\n  --pmpnn_relax_cycles=1 \\\n  -profile local \\\n  -resume\n\n#   --rfd_filters=\"rg&lt;=20\" \\\n\n(this is actually a slightly simiplified version of one of the examples in the nf-binder-design Github repository)\n\nYou can see all the options available with:\nnextflow run Australian-Protein-Design-Initiative/nf-binder-design --help\n\n\n\n\n\n\nTip\n\n\n\nAs a general rule, parameters are named to match the underlying tool, with an rfd_, pmpnn_ or af2fig prefix. Extra parameters can be configured via --rfd_extra_args or a nextflow.config file:\n// nextflow.config\nprocess {\n    withName: RFDIFFUSION {\n        ext.args = 'potentials.guiding_potentials=[\\\"type:binder_ROG,weight:7,min_dist:10\\\"] potentials.guide_decay=\"quadratic\"'\n    }\n}\nNote the use of ' single quotes and escaped \\\" double quotes - this is important to ensure the string is passed correctly to the RFdiffusion command.",
    "crumbs": [
      "RFdiffusion (& ProteinMPNN)",
      "RFdiffusion Exercise"
    ]
  },
  {
    "objectID": "target_preparation.html",
    "href": "target_preparation.html",
    "title": "Target preparation",
    "section": "",
    "text": "So, you want to de novo design a binder for a target protein …",
    "crumbs": [
      "Target Preparation",
      "Target preparation"
    ]
  },
  {
    "objectID": "target_preparation.html#things-to-consider",
    "href": "target_preparation.html#things-to-consider",
    "title": "Target preparation",
    "section": "Things to consider",
    "text": "Things to consider\n\nDo I have an experimental structure of the target ?\n\nIs it high quality / well defined in the regions required ?\nIf I don’t have an experimental structure, are computational models (eg Alphafold) reliable for this target - do I believe them based on other data, biology ?\n\nIs this a good experimental/clinical target ?\n\nWhat characteristics should be designed binders have to be better/cheaper/safer/unique relative to existing tools or therapies ?\nIn the assay or biological system, will the target surfaces be accessible, or how will my binder get there ?\n\nHow will produce and test my de novo binders ?\n\nDo I have a reliable medium-high throughput assay ?",
    "crumbs": [
      "Target Preparation",
      "Target preparation"
    ]
  },
  {
    "objectID": "target_preparation.html#truncation-trimming-cropping",
    "href": "target_preparation.html#truncation-trimming-cropping",
    "title": "Target preparation",
    "section": "Truncation, trimming, cropping",
    "text": "Truncation, trimming, cropping\n\n“Truncating a target is an art.” – Nathaniel Bennett, RFdiffusion README.md\n\nFor RFdiffusion, runtime scales at O(N^2) where N is the number of residues.\nFor BindCraft, 500 residues (target+binder) uses ~30Gb GPU memory.\nIt is very common, and good practise, to remove parts of the target coordinates to speed up computation of binders, and make better use of in-demand GPU resources. Sometimes truncation is the difference between practical (24G VRAM), possible (A100-80G or GH200-96G) and not (yet) possible ( &gt;141G VRAM on a single device).\n\nTry to keep distinct (sub)domains intact\nTry to avoid exposing the hydrophobic core\nDon’t truncate too close to your proposed binding interface and hotspots\n\n\n\n\n\n\n\nCautionChallenge - truncate PD-L1\n\n\n\nGrab the cooridinates for the PD-1/PD-L1 complex 3BIK (legacy PDB format).\nWe want to use PD-L1 (chain A) as our target and block the binding of PD-1 (chain B).\nPropose a truncated version of PD-L1 (chain A) we could use to design a de novo binder against.\n(Save the truncated coordinates as PDL1.pdb)\n\n\n\nHotspot selection\nIn the context of de novo binder design, a ‘hotspot’ is residue on the target that is likely to make favourable interactions with residues on the de novo binder. Hotspots help guide the location and characteristics of the binder-target interface and can have a large (not always predictable) impact on in silico success rates.\nFor RFdiffusion, 3–6 hotspots are recommended (RFdiffusion attempts to put between 0 and 20% of these hotspots, at random, within 10Å of a binder Cβ atom, while making any other contacts that appear statistically plausible to the model).\nFor BindCraft, zero to X hotspots. Starting with a small number (1 - 3 ?) of hotspots is probably best.\nAromatic and hydrophobic residues (F, Y, W, I, L, M) tend to make the best hotspots, but you don’t need to restrict your choices to only these residue types.\n\n\n\n\n\n\nCautionChallenge - PD-L1 hotspots\n\n\n\nLook at the residues at the interface of PD-1/PD-L1 in 3BIK.\nPropose three residues on PD-L1 (chain A) we might choose as hotspots to design a de novo binder to block interaction of PD-1.",
    "crumbs": [
      "Target Preparation",
      "Target preparation"
    ]
  },
  {
    "objectID": "introduction.html",
    "href": "introduction.html",
    "title": "Introduction",
    "section": "",
    "text": "Introduction\nPost-Alphafold2, new deep learning methods in de novo protein design have emerged with unprecedented success rates for folding and activity generated sequences.\nThis workshop aims to explore one key design goal - generating small proteins in silico that bind to a target protein with high affinity and specificity.\nWe will use two leading methods - one based on RFdiffusion, one and using BindCraft.\n\n\nScores, so many scores\nIt’s worth recapping many of the different scores that Alphafold (and other related structure prediction tools) generally use to assess confidence, since these are also key scores that are used for generating and filtering de novo binder designs.\n\npLDDT - predicted “local distance test”\n\nbased on the lDDT-Cα score for comparing local Cα distances between predicted and experimental structures\n‘Real’ lDDT-Cα scores are based on the average fraction of preserved distances between each Cα atom in four distance thresholds of 0.5 Å, 1 Å, 2 Å, and 4 Å\nAlphafold2 was trained to predict lDDT-Cα as a measure of local confidence by using real lDDT values between ground truth experimental structures and its predictions.\n\n\n\n\n\n\n\nNotepLDDT Interpretation\n\n\n\nRange: 0 → 100 (or sometimes expressed as 0.0 → 1.0).\nHigher is more confident.\n\n\n\n\nPAE - predicted aligned error\n\nthe confidence in the relative position of each residue pair in the predicted structure, measured in Ångströms (Å)\nthe expected positional error at residue X, if the predicted and ground truth structures were aligned on residue Y.\nUsually visualized as a 2D heatmap of the predicted aligned error for each residue pair.\n\n\n\n\n\n\n\nNotePAE Interpretation\n\n\n\nRange: 0.0 → ~30 Å (Ångströms)\nNot a single value, but often averaged over groups of residue pairs (intra or inter-chain).\nLower suggests a more accurate prediction.\n\n\n\n\npae_interaction - inter-chain predicted aligned error\n\nsometimes called iPAE, or i_pAE\nThe average PAE score for inter-chain residue pairs in the PAE matrix, between target and binder.\nEg, the average pAE every pair that is not and intra-domain PAE score.\na measure of confidence in the relative arrangement of the target and binder.\n\n\n\n\n\n\n\nNotepae_interaction Interpretation\n\n\n\nRange: 0.0 → 100 (or sometimes expressed as 0.0 → 1.0).\nHigher is more confident.\n\n\n\n\n\n\n\n\n\n\nPAE Matrix for pae_interaction\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nResidue Index (Rows)\n0\nBinder\nTarget\n\n\nResidue Index (Columns)\n0\nBinder\nTarget\n\n\nIntra-Binder PAE\npae_interaction1\npae_interaction2\nIntra-Target PAE\n\n\n\n  \n    paeinteraction = mean( paeinteraction1 + paeinteraction2 )\n  \n\n\n\n\n\n\nthe ‘other’ iPAE\n\nothers have used the name iPAE defined as the median PAE of interface residues (where interface residues are those &lt; 3.5 Å from the binding partner).\nthe tools in the workshop don’t use this score\n\n\n\n\npTM - predicted template modelling (TM) score\n\nan overall measure of structure accuracy - Alphafold2 (ptm) models, and Alphafold Multimer models, are trained to predict TM-score between the predicted and experimental structures.\nThe original non-predicted TM-score is based on the C\\(\\alpha\\) distances between the predicted and experimental structures, with poorly superimposing C\\(\\alpha\\) atoms downweighted, and a scaling factor to normalise for the length of the protein (for the best superimposition, that maximises the TM-score).\nTM-score is less sensitive to outliers than RMSD (flexible loops and tails have a smaller impact), and independent of protein length\n\n\n\n\n\n\n\nNotepTM Interpretation\n\n\n\nRange: 0.0 → 1.0\nHigher is more confident - \\(&lt; ~0.17\\) is completely random\n\n\\(&gt; 0.5\\) is likely the same fold\n\\(1.0\\) is an identical structure ```\n\n\n\n\n\nipTM - interface predicted template modelling (TM) score\n\nlike the pTM score, but considers only pairs of residues between chains, not within chains (inter-chain pairs only)\na measure of confidence in the relative arrangement of the target and binder.\n\n\n\n\n\n\n\nNoteipTM Interpretation\n\n\n\nRange: 0.0 → 1.0\nHigher is more confident\n\n\\(&gt; 0.6\\), might be a real complex\n\\(&gt; 0.8\\), probably a real complex\n\n\n\n\n\nC\\(\\alpha\\)-RMSD - root mean square deviation of C\\(\\alpha\\) atoms\n\ncalculated between two superimposed structures\ncan be sensitive to outliers (flexible loops and tails), but often outliers are excluded from the calculation (eg ChimeraX ‘matchmaker’ reports RMSD values for ‘pruned’ and ‘all’ pairs of atoms)\ndepends non-linearly on protein length (longer proteins will tend to have higher RMSD values)\n\n\n\n\n\n\n\nNoteRMSD (C\\(\\alpha\\)) Interpretation\n\n\n\nRange: 0.0 → … ∞ ?\nLower is more confident\n\n\n\n\n\n\n\n\n\nTipPredicting affinity\n\n\n\nTo date, none of these scores (or others) have been found to strongly associate with binding affinity in the high affinity ranges (≫10 μM) we are usually interested in.\nMany do tend to associate with boolean binding/non-binding (eg predicting less than or greater than 10 μM affinity), so they are still useful for guiding and filtering designs in silico.\n\n\n\n\n\nResources\n\nEBI Alphafold tutorial: good practical overviews of pLDDT, PAE, TM, pTM, ipTM.\n\n\n\n\n\nReuseCC BY 4.0",
    "crumbs": [
      "Workshop",
      "Introduction"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Protein binder design workshop: RFdiffusion and BindCraft",
    "section": "",
    "text": "Important links\n\nTODO: Insert link to shared Google Doc / Slack channel / other in here. The Google doc, editable by all participants, can be used as a jumping off point for other dynamic links and administrative info we may need to update during the workshop (like the VM login details). It can also be used also be used by participants for posting challenge solutions.\n\n\n\nSchedule\n\n\n\nTime\nEvent\n\n\n\n\n1:00\nWelcome and introduction\n\n\n1:30\nRFdiffusion\n\n\n2:30\nBreak\n\n\n2:45\nBindCraft\n\n\n3:45\nBreak\n\n\n4:00\nExperimental validation\n\n\n4:30\nWrap-up and discussion\n\n\n4:45\nEnd 🎉\n\n\n\n\n\n\nAcknowledgements\nMany thanks to Monash eResearch HPC team for providing the compute resources and associated support for this workshop.\n\n\n\n\nReuseCC BY 4.0",
    "crumbs": [
      "Workshop",
      "Protein binder design workshop: RFdiffusion and BindCraft"
    ]
  },
  {
    "objectID": "structure_prediction.html",
    "href": "structure_prediction.html",
    "title": "Structure prediction",
    "section": "",
    "text": "Structure prediction\nOnce sequences have been generated for the backbone design via inverse folding, we want to predict more accurately if this binder sequence is likely to fold into the correct structure.\nThis allows us to assess the quality of the proposed protein-protein interface.\n\nAlphafold scores: pLDDT, PAE, pae_interaction, TM, pTM, ipTM, oh my !\n\nhttps://www.ebi.ac.uk/training/online/courses/alphafold/\n\n\naf2_initial_guess vs. Alphafold2 (vs. ColabFold modes vs. other structure prediction tools)\n\n\n\n\nReuseCC BY 4.0"
  },
  {
    "objectID": "rfdiffusion_background.html",
    "href": "rfdiffusion_background.html",
    "title": "RFdiffusion Background",
    "section": "",
    "text": "We will start by using the RFdiffusion binder design protocol, as described in the following papers:\n\nWatson, J.L., Juergens, D., Bennett, N.R. et al. “De novo design of protein structure and function with RFdiffusion.”, Nature, 620, 1089–1100 (2023). https://doi.org/10.1038/s41586-023-06415-8 - Github: https://github.com/RosettaCommons/RFdiffusion\nBennett, N.R., Coventry, B., Goreshnik, I. et al. Improving de novo protein binder design with deep learning. Nat Commun, 14, 2625 (2023). https://doi.org/10.1038/s41467-023-38328-5 - Github: https://github.com/nrbennet/dl_binder_design\nDauparas, J. et al. Robust deep learning–based protein sequence design using ProteinMPNN. Science, 378,49-56(2022). https://doi.org/10.1126/science.add2187 - Github: https://github.com/dauparas/ProteinMPNN\n\nThis method combines:\n\nRFdiffusion for ‘hallucinating’ the backbone of a designed binder for a target structure\nProteinMPNN for ‘inverse folding’ to generate a sequence for the binder backbone\nAlphafold2 ‘initial guess’ structure prediction to quickly score binders in silico",
    "crumbs": [
      "RFdiffusion (& ProteinMPNN)",
      "RFdiffusion Background"
    ]
  },
  {
    "objectID": "rfdiffusion_background.html#background",
    "href": "rfdiffusion_background.html#background",
    "title": "RFdiffusion Background",
    "section": "",
    "text": "We will start by using the RFdiffusion binder design protocol, as described in the following papers:\n\nWatson, J.L., Juergens, D., Bennett, N.R. et al. “De novo design of protein structure and function with RFdiffusion.”, Nature, 620, 1089–1100 (2023). https://doi.org/10.1038/s41586-023-06415-8 - Github: https://github.com/RosettaCommons/RFdiffusion\nBennett, N.R., Coventry, B., Goreshnik, I. et al. Improving de novo protein binder design with deep learning. Nat Commun, 14, 2625 (2023). https://doi.org/10.1038/s41467-023-38328-5 - Github: https://github.com/nrbennet/dl_binder_design\nDauparas, J. et al. Robust deep learning–based protein sequence design using ProteinMPNN. Science, 378,49-56(2022). https://doi.org/10.1126/science.add2187 - Github: https://github.com/dauparas/ProteinMPNN\n\nThis method combines:\n\nRFdiffusion for ‘hallucinating’ the backbone of a designed binder for a target structure\nProteinMPNN for ‘inverse folding’ to generate a sequence for the binder backbone\nAlphafold2 ‘initial guess’ structure prediction to quickly score binders in silico",
    "crumbs": [
      "RFdiffusion (& ProteinMPNN)",
      "RFdiffusion Background"
    ]
  },
  {
    "objectID": "rfdiffusion_scoring.html",
    "href": "rfdiffusion_scoring.html",
    "title": "RFdiffusion : analysing a full design run",
    "section": "",
    "text": "“Here’s one we prepared earlier” - 500 designs using the RFdiffusion binder design workflow of nf-binder-design are in /scratch2/pd27/shared/examples/nfbd/pdl1-rfd.",
    "crumbs": [
      "RFdiffusion (& ProteinMPNN)",
      "RFdiffusion : analysing a full design run"
    ]
  },
  {
    "objectID": "rfdiffusion_scoring.html#other-scores",
    "href": "rfdiffusion_scoring.html#other-scores",
    "title": "RFdiffusion : analysing a full design run",
    "section": "Other scores",
    "text": "Other scores\n\nTODO: Rosetta gG energy ?",
    "crumbs": [
      "RFdiffusion (& ProteinMPNN)",
      "RFdiffusion : analysing a full design run"
    ]
  },
  {
    "objectID": "bindcraft_exercise.html",
    "href": "bindcraft_exercise.html",
    "title": "BindCraft Exercise",
    "section": "",
    "text": "BindCraft requires a JSON format configuration file to define parameters for the design. Create the file below as settings.json:\n{\n    \"design_path\": \"bindcraft_results\",\n    \"binder_name\": \"pdl1_binder\",\n    \"starting_pdb\": \"./input/PDL1.pdb\",\n    \"chains\": \"A\",\n    \"target_hotspot_residues\": \"A56\",\n    \"lengths\": [\n        55,\n        120\n    ],\n    \"number_of_final_designs\": 1\n}\nWe have chosen a single hotspot here (as \"{chain}{resnum}\") - multiple hotspots can be comma separated like \"A56,A54,A115\".\nNormally you’d like to generate more than a single design (maybe \"number_of_final_designs\": 100 ?) - today we barely have time for one !\n\n\n\nmodule load bindcraft/.05702c4\n \nbindcraft.py \\\n    --settings settings.json\n\n# We won't override any default settings or filters\n#    --filters /app/BindCraft/settings_filters/default_filters.json \\\n#    --advanced /app/BindCraft/settings_advanced/default_4stage_multimer.json\nBindCraft runs can be resumed from where they left off just by running the command again - it will determine if the number of accepted designs has been met, and if not, continue.\n\nIt’s safe to Ctrl-C kill a BindCraft run, only the progress on the current trajectory is lost.\n\n--filters and --advanced are optional - in our example they point to the default config files (inside the Apptainer container). You could specify your own, based on those found in the BindCraft Github repository.\n\nUnless you are embarking on a study to experimentally verify the impact of different filters or advanced settings on success rates, it is safest to use the defaults which have been more heavily tested by the BindCraft authors, since these are what have been used to achieve the published wet-lab success rates.\n\n\n\n\nWe configured BindCraft to put results in the bindcraft_results directory.\nIn here we have, of most interest:\n\nfinal_design_stats.csv - a CSV file summarizing the results of the BindCraft run\nAccepted/ - a directory containing the PDB files of the accepted designs (missing if no designs were accepted)\n\nas well as:\n\nfailure_csv.csv - a CSV file summarizing the stage where a design failed to pass a filter\nTrajectory/ - various non-accepted trajectories MPNN/ - PDB files of alternative ProteinMPNN designs for each trajectory that passed the initial filters\ntrajectory_stats.csv and mpnn_design_stats.csv - scores for trajectories / designs at the initial hallucination stage and the ProteinMPNN sequence generation stage\n\nWe will focus on understanding the key outputs here in the next section.",
    "crumbs": [
      "BindCraft",
      "BindCraft Exercise"
    ]
  },
  {
    "objectID": "bindcraft_exercise.html#configuration",
    "href": "bindcraft_exercise.html#configuration",
    "title": "BindCraft Exercise",
    "section": "",
    "text": "BindCraft requires a JSON format configuration file to define parameters for the design. Create the file below as settings.json:\n{\n    \"design_path\": \"bindcraft_results\",\n    \"binder_name\": \"pdl1_binder\",\n    \"starting_pdb\": \"./input/PDL1.pdb\",\n    \"chains\": \"A\",\n    \"target_hotspot_residues\": \"A56\",\n    \"lengths\": [\n        55,\n        120\n    ],\n    \"number_of_final_designs\": 1\n}\nWe have chosen a single hotspot here (as \"{chain}{resnum}\") - multiple hotspots can be comma separated like \"A56,A54,A115\".\nNormally you’d like to generate more than a single design (maybe \"number_of_final_designs\": 100 ?) - today we barely have time for one !",
    "crumbs": [
      "BindCraft",
      "BindCraft Exercise"
    ]
  },
  {
    "objectID": "bindcraft_exercise.html#run-bindcraft",
    "href": "bindcraft_exercise.html#run-bindcraft",
    "title": "BindCraft Exercise",
    "section": "",
    "text": "module load bindcraft/.05702c4\n \nbindcraft.py \\\n    --settings settings.json\n\n# We won't override any default settings or filters\n#    --filters /app/BindCraft/settings_filters/default_filters.json \\\n#    --advanced /app/BindCraft/settings_advanced/default_4stage_multimer.json\nBindCraft runs can be resumed from where they left off just by running the command again - it will determine if the number of accepted designs has been met, and if not, continue.\n\nIt’s safe to Ctrl-C kill a BindCraft run, only the progress on the current trajectory is lost.\n\n--filters and --advanced are optional - in our example they point to the default config files (inside the Apptainer container). You could specify your own, based on those found in the BindCraft Github repository.\n\nUnless you are embarking on a study to experimentally verify the impact of different filters or advanced settings on success rates, it is safest to use the defaults which have been more heavily tested by the BindCraft authors, since these are what have been used to achieve the published wet-lab success rates.",
    "crumbs": [
      "BindCraft",
      "BindCraft Exercise"
    ]
  },
  {
    "objectID": "bindcraft_exercise.html#bindcraft-output",
    "href": "bindcraft_exercise.html#bindcraft-output",
    "title": "BindCraft Exercise",
    "section": "",
    "text": "We configured BindCraft to put results in the bindcraft_results directory.\nIn here we have, of most interest:\n\nfinal_design_stats.csv - a CSV file summarizing the results of the BindCraft run\nAccepted/ - a directory containing the PDB files of the accepted designs (missing if no designs were accepted)\n\nas well as:\n\nfailure_csv.csv - a CSV file summarizing the stage where a design failed to pass a filter\nTrajectory/ - various non-accepted trajectories MPNN/ - PDB files of alternative ProteinMPNN designs for each trajectory that passed the initial filters\ntrajectory_stats.csv and mpnn_design_stats.csv - scores for trajectories / designs at the initial hallucination stage and the ProteinMPNN sequence generation stage\n\nWe will focus on understanding the key outputs here in the next section.",
    "crumbs": [
      "BindCraft",
      "BindCraft Exercise"
    ]
  },
  {
    "objectID": "bindcraft_exercise.html#recommendations",
    "href": "bindcraft_exercise.html#recommendations",
    "title": "BindCraft Exercise",
    "section": "Recommendations",
    "text": "Recommendations\n\nChoose some hotspots based on the strategies we’ve learned.\nRun between 100 and 300 trajectories (--bindcraft_n_traj 300) to assess the ‘acceptance rate’\n\nIf you are getting a reasonable acceptance rate, &gt; ~%1, do a second run setting --bindcraft_n_traj to a value that should generate ~100 accepted designs\nIf you are getting less than ~1% acceptance rate, you may need to change your hotspots, modify target trimming or use a different target structure, or (cautiously) use advanced presets.\n\n\nThe percentage acceptance rate is:\n\\[\\text{Acceptance Rate} = 100 \\times \\frac{n_{\\text{accepted}}}{N_{\\text{traj}}}\\]\nwhere:\n\n\\(n_{\\text{accepted}}\\) = number of accepted designs\n\\(N_{\\text{traj}}\\) = total number of trajectories\n\n\n(From my interpretation of the BindCraft source code, when using the default \"max_mpnn_sequences\": 2, the maximum acceptance rate is 200% ¯\\_(ツ)_/¯ )\n\nAs a guide, the BindCraft authors recommend generating ~100 ‘accepted’ designs and choosing the best 20 for experimental assay. ‘Best’ is likely highest Average_i_pTM, but you may also choose additional criteria based on what you know about the target or biology.",
    "crumbs": [
      "BindCraft",
      "BindCraft Exercise"
    ]
  },
  {
    "objectID": "bindcraft_tips.html",
    "href": "bindcraft_tips.html",
    "title": "BindCraft : tips and guidance",
    "section": "",
    "text": "These tips are taken directly from the BindCraft wiki page and BindCraft paper supplementary info, but reformatted to be more concise and readable, with a few extra tips:\n\n\nInstallation\n\nSystem Requirements: Runs exclusively on Linux systems with conda or mamba.\nCUDA & JAX: Specify your CUDA version during installation to avoid version conflicts, especially with JAX.\nDependencies: Uses ColabDesign, ProteinMPNN, and PyRosetta. Commercial users need a PyRosetta license.\nEnvironment Path: If the conda environment fails to activate, its path can be manually specified in the run script.\nExecution: Designed for HPC clusters with SLURM but can be run locally via bash or python scripts.\nApptainer containers: are also available (eg ) - these can simplify installation when the provided install_bindcraft.sh script fails\n\n\n\n\nHardware Considerations\n\nGPU: A CUDA-compatible NVIDIA GPU is mandatory. Recommended models include L40, V100, A100, or H100.\n\nAn H100 GPU is roughly 4 times faster than an A100.\neg, on H100: 900 residue trajectory == 2-3 hours, 250 residue trajectory == 5 minutes\n\nGoogle Colab: Can be run on Colab, but it is approximately 10 times slower than a local installation with the same hardware.\nGPU Memory: This is the primary bottleneck. A 32 Gb card handles a complex of ~550 residues, while an 80 Gb card manages ~950 residues.\nParallelization: The core process cannot be split across multiple GPUs, but you can run multiple separate jobs outputting to the same folder to speed up sampling.\nStorage: A few terabytes are recommended. The model weights alone are 5.3 Gb. You can save space by disabling plot and animation outputs.\nCPU & RAM: A single CPU core is usually sufficient. At least 40 Gb of RAM is recommended to avoid out-of-memory errors from model compilation or PyRosetta features.\n\n\n\n\nGetting Started\n\nInput: Requires a target protein structure (PDB), a binder size range, and the desired number of designs.\nBinder Size:\n\nGlobular binders: Optimal between 60-180 amino acids (max reliable size is 250 AAs).\nPeptide binders: 8-25 amino acids, requiring special peptide settings and filters. Peptide design success rates are typically 5-10 times lower.\n\nHotspots: You can specify “hotspot” residues for the binder to target. If none are provided, the pipeline finds an optimal site on its own.\nMonitoring & Early Stopping:\n\nCheck the Accepted folder during the run to manually remove unsuitable designs.\nThe script may terminate prematurely if design success rates are too low, saving computational resources.\nTo stop early and rank current designs, kill the jobs, set the design count lower than what’s in the Accepted folder, and rerun.\n\nRun Time: Can vary from a few hours to several weeks on a single GPU, depending on target difficulty and complex size.\n\n“Easy” targets might only require ~100 trajectories, difficult ones might required 1000 - 10,000.\nIt’s possible for difficult targets to yield no successful designs.\n\n\n\n\n\nUnder the Hood\n\nCore Method: Uses backpropagation through the AlphaFold2 multimer network in MSA-free (single sequence) mode.\nSequence Generation: Optimizes the sequence in a “relaxed” (soft) space before converting it to a standard one-hot encoded sequence.\nSelf-Consistency Checks:\n\nModel Swapping: Randomly swaps between the five trained AlphaFold2 multimer models during design to ensure robustness and avoid overfitting.\nSequence Optimization: Uses ProteinMPNN to refine the binder’s core and surface while preserving the designed interface. This is done because purely hallucinated sequences can be difficult to purify experimentally.\n\nBy default, “soluble” MPNN weights are used, which usually result in a negatively charged binder surface. “Original” weights can be used for a more neutral surface.\n\nMonomer Reprediction: Uses the AlphaFold2 monomer model for the final prediction. Since this model was not trained on complexes, it serves as a highly stringent test of a well-defined interface.\nBinder Folding Check: The binder is also repredicted alone (without the target) to assess its structural change (RMSD) upon binding.\n\nFinal Analysis: PyRosetta is used to calculate interface scores and provide additional biophysical metrics for filtering (eg Rosetta dG, surface hydrophobicity, shape complementarity, number of interface residues, H-bonds and unsaturated H-bonds).\nOutput Structure: Designs are collected in sequential folders (Trajectory → MPNN → Accepted) with corresponding metrics in separate CSV files.\n\n\n\n\nTarget Preparation & Hotspot Selection\n\nInput Structure:\n\nAccepts experimental (NMR, CryoEM)\nor predicted (AlphaFold2, Boltz-2 etc) PDBs.\n\nUsing an experimental structure as a template for a new AlphaFold2 or Boltz-2 prediction can help fill in missing loops.\n\nEven small variations of the ‘same’ target (experimental vs. predicted vs. alternative trimming) can change in silico success rates significantly.\n\nTrimming:\n\nTrim the target to only essential domains to save memory and time. Remove flexible ends and large flexible loops if these are not involved in the binding interface.\nTrim at realistic points like domain boundaries or hinge residues (e.g., Gly, Pro), which can be identified by high B-factors or low pLDDT scores.\n“Unrealistic” trims (e.g., splitting GPCR helices) are supported if they preserve the local structural context and don’t expose core hydrophobic residues.\n\nHotspot Selection:\n\nDefine hotspots by residue number and chain ID (e.g., A23,A27-50,B45).\nTargeting a radial patch of surface residues on secondary structures is recommended, especially sites containing hydrophobic residues (F, Y, W, I, L, M).\nSingle residues also work in well defined binding sites. You can also leave hotspots undefined and let the model choose.\n\nOff-Target Binding: your hotspots may be ignored if the choice of target site is suboptimal or if there is a significantly better binding site nearby. To encourage your preferred binding site you can:\n\nMutate the unwanted binding site residues to lysines.\nTrim away the off-target region.\nUse the _hardtarget advanced setting.\nPre-block the off-target binding site with another binder ! First generate a design that binds to the off-target site, and use this new complex as a structural input for a new run.\n\n\n\n\n\nAdvanced Settings\n\nDefault Settings (default_): Extensively tested and recommended for the highest chance of success.\n_hardtarget:\n\nSets \"predict_initial_guess\": true.\nBiases the prediction by providing binder atom positions as a starting point. Can help rescue designs that fail after the MPNN step. (As of late 2025 this setting has not been systematically tested and is likely to reduce success rates).\n\n_flexible:\n\nSets \"rm_template_seq_design/predict\": true.\nMasks the target’s amino acid sequence, which allows for greater backbone flexibility and domain movements during design and reprediction.\n\n_mpnn:\n\nSets \"mpnn_fix_interface\": false.\nAllows ProteinMPNN to redesign and optimize the interface residues, rather than keeping the AlphaFold2-designed interface fixed.\n\n_betasheet:\n\nEnforces beta-sheet structures by penalizing helicity (\"weights_helicity\": -2.0).\n\n_peptide:\n\nUses a 3stage algorithm instead of the default 4stage.\nChanges multiple loss weights to favour peptide-like properties (e.g., increases helicity weight, reduces contact weights).\nDoes not use the radius of gyration (rg_loss).\n\n\"predict_bigbang\": true setting:\n\nFor complexes &gt; 600 residues, this setting facilitates more efficient prediction of large complexes in the final stage\n\n\n\n\n\nFiltering\n\nDefault Filters: The default filters are robust and generally should not be changed, except when designing peptides.\nKey Metrics: The most important metrics for filtering are pLDDT, i_pTM, and i_pAE.\n\nThe i_pTM score is a good binary predictor of binding, but values between 0.6 and 0.8 are a “grey zone” where predictions can be incorrect.\n\nAffinity: None of the computational metrics are predictive of binding affinity.\nEarly Rejection: Trajectories are terminated early if they have:\n\nCA clashes &gt; 0 or Interface clashes &gt; 25.\npLDDT &lt; 0.7.\nA “floating” binder with &lt; 3 contacts to the target.\n\nBinder RMSD Filter: This filter can be relaxed or disabled if more conformational flexibility or an “induced fit” binder is desired.\n\n\nDefault filters\nDesigns that satisfy these critera are kept as ‘Accepted’:\n\nAlphaFold2 Metrics\n\nAverage_pLDDT &gt; 0.8\nAverage_pTM &gt; 0.55\nAverage_i_pTM &gt; 0.5\nAverage_i_pAE &lt; 0.35\n\nRosetta Metrics\n\nAverage_Binder_Energy_Score &lt; 0\nAverage_Surface_Hydrophobicity &lt; 0.35\nAverage_ShapeComplementarity &gt; 0.6\nAverage_dG &lt; 0\nAverage_dSASA &gt; 1\nAverage_n_InterfaceResidues &gt; 7\nAverage_n_InterfaceHbonds &gt; 3\nAverage_n_InterfaceUnsatHbonds &lt; 4\nAverage_InterfaceAAs: K &lt; 3\nAverage_InterfaceAAs: M &lt; 3\n\nStructural Metrics\n\nAverage_Binder_Loop% &lt; 90\nAverage_Hotspot_RMSD &lt; 6\nAverage_Binder_pLDDT &gt; 0.8\nAverage_Binder_RMSD &lt; 3.5\n\n\n\n\n\n\nDesign Selection\n\nQuantity: Generate at least 100 designs that pass filters to ensure good sampling of interface diversity.\nRanking: Final designs in the Accepted/Ranked folder are ranked by i_pTM. This is for prioritization only; all designs that pass filters are high-quality candidates.\nSub-selection:\n\nPrioritize sampling diverse interfaces over similar designs from the same trajectory.\nPerform a final visual check in PyMOL or ChimeraX.\nConsider repredicting top candidates in the context of the full biological complex and check that the target interface is free of post-translational modifications.\n\nExperimental Success:\n\nScreening ~10 designs is often sufficient to find a nanomolar binder.\nScreening 50-100 designs is recommended when aiming for picomolar affinity.\nGenerated binders are typically well-behaved biochemically (thermostable, easy to purify).\n\n\n\n\n\nTroubleshooting\n\nMismatched Atoms Error: Your input PDB likely has partial residues or atoms left over from trimming. Clean the file before rerunning.\nBinder Ignores Hotspots: This is an intended feature to avoid forcing binders into poor sites. See the “Target Preparation” section for strategies to enforce binding to a specific site.\n\n\n\n\n\nReuseCC BY 4.0",
    "crumbs": [
      "BindCraft",
      "BindCraft : tips and guidance"
    ]
  },
  {
    "objectID": "experimental_validation.html",
    "href": "experimental_validation.html",
    "title": "Experimental Validation",
    "section": "",
    "text": "So, you’ve designed some de novo binders. You’ve filtered them based on some in silico scores and other criteria to your preferences and have a ranked set of ~96 sequences.",
    "crumbs": [
      "Next steps",
      "Experimental Validation"
    ]
  },
  {
    "objectID": "experimental_validation.html#gene-synethesis-protein-purfication-and-experimental-assays",
    "href": "experimental_validation.html#gene-synethesis-protein-purfication-and-experimental-assays",
    "title": "Experimental Validation",
    "section": "Gene synethesis, protein purfication and experimental assays",
    "text": "Gene synethesis, protein purfication and experimental assays\nWhat next ? You’ll need to consider:\n\nAffinity tag placement\n\nMost likely you’ll need an affinity tag - which terminii should this be on for each design ?\n\nPadding for gene synthesis\n\nDepending on the service provider, you may need to add additional non-coding padding sequence to your construct (eg Twist might require a minimum insert size of 300bp).\n\nExpression system\n\nWhat vector system do you need to use to produce your protein for assay ?\nWill you clone the fragment library yourself, or will the service provider do this for you ?\nWhat vectors are available from the service provider ?\n\nHow will you express and purify ~96 proteins ?\nHow will you assess expression level and solubility ?\nWhat level of purity, concentration and buffer conditions you need for your assay ?\n\nMany of these considerations will be familiar to experimental structural biologists, but it’s worth considering the practicalities of how you will deal with scaling up from a handful of constructs to ~96 or more.",
    "crumbs": [
      "Next steps",
      "Experimental Validation"
    ]
  },
  {
    "objectID": "experimental_validation.html#expected-experimental-hit-rates",
    "href": "experimental_validation.html#expected-experimental-hit-rates",
    "title": "Experimental Validation",
    "section": "Expected experimental ‘hit’ rates",
    "text": "Expected experimental ‘hit’ rates\nHow do we define successful binding ? A typical definition used is Kd &lt;= 10uM.\nRFDiffusion with published in silico scoring thresholds, has a success rate of between 7% to 35% (depending on the target).\nBindCraft has published success rate of between 10% to 100% (depending on the target).",
    "crumbs": [
      "Next steps",
      "Experimental Validation"
    ]
  },
  {
    "objectID": "bash_apptainer_crash_course.html",
    "href": "bash_apptainer_crash_course.html",
    "title": "Foundational skills: Bash shell and Apptainer crash course",
    "section": "",
    "text": "The Unix shell\nIf you need a refresher on the basics of the Unix shell, there are already great resources available, please see one of:\n\n“The Shell” at Linux Journey\n“Terminal basics” at sandbox.bio\nIntroduction to Unix (at Andrew Robinson / LaTrobe University)\n\n\n\nApptainer\nFor an in-depth workshop, see Reproducible computational environments using containers: Introduction to Apptainer.\nHere’s a crash course.\nSetting your cache path - this is where Apptainer will download container images to:\nexport APPTAINER_CACHEDIR=$HOME/.apptainer/apptainer_cache\nDownloading a container image:\napptainer pull docker://ghcr.io/australian-protein-design-initiative/containers/bindcraft:05702c4_nv-cuda12\nDownloading a container image to a (large) file anywhere:\napptainer pull bindcraft.sif docker://ghcr.io/australian-protein-design-initiative/containers/bindcraft:05702c4_nv-cuda12\n… this will create a self-contained file called bindcraft.sif in your current directory. You can run things inside the container like:\napptainer exec bindcraft.sif python --version\nWe will continue to use the image in APPTAIENR_CACHEDIR, instead: rm bindcraft.sif\n\nStarting a shell session ‘inside’ a container:\napptainer shell docker://ghcr.io/australian-protein-design-initiative/containers/bindcraft:05702c4_nv-cuda12\nThis is useful for ‘exploring’ what’s inside the container. For example, while ‘inside’ the BindCraft container, try:\ncd /app/BindCraft\nls settigns_advanced/\nType exit or press Ctrl-D to return to your regular shell.\n\nRather than writing the image URL every time, docker://ghcr.io/australian-protein-design-initiative/containers/bindcraft:05702c4_nv-cuda12 every time, let’s set it as a shell variable - this makes the commands below easier to read:\nexport BINDCRAFT_IMAGE=\"docker://ghcr.io/australian-protein-design-initiative/containers/bindcraft:05702c4_nv-cuda12\"\nRunning a command in a container:\napptainer exec $BINDCRAFT_IMAGE python --version\nMounting (‘binding’) a directory so it’s visible inside a container - eg -B ~/my_data:\napptainer exec -B ~/my_data $BINDCRAFT_IMAGE ls ~/my_data\nMounting (‘binding’) a directory at a different path inside a container - eg -B ~/my_data:/data:\napptainer exec -B ~/my_data:/data $BINDCRAFT_IMAGE ls ~/my_data\nTry to pretend there is no container:\n# Add this to your .bashrc or .zshrc to make it permanent\nalias bindcraft='apptainer exec $BINDCRAFT_IMAGE'\n\nbindcraft --help\n\n\n\n\nReuseCC BY 4.0",
    "crumbs": [
      "Appendix",
      "Foundational skills: Bash shell and Apptainer crash course"
    ]
  }
]